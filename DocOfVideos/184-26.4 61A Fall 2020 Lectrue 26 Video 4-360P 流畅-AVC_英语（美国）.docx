okay where'd we leave off uh so here's what we know we know that commercial software being used to predict recidivism is not particularly accurate 65 accurate and seems to have a racial bias issue number one number two is that when we pulled people on the internet uh on mechanical turk to do a similar task they had the same accuracy as the commercial ai software and they seem to have the same racial bias despite the fact that they don't have information about race so whether they knew race or not they had that same bias in terms of the errors they were being making so that leads us to two questions how is it that both the software and the humans not knowing race are not race blind that's weird and we should understand that and perhaps more importantly is that how is it that ai being used in the court is as accurate and as biased as random people on the internet these aren't even judges lawyers social workers and people in the criminal justice system these are people being paid a few bucks on the internet and we need to get to the bottom of both of these and that's what we're going to do in this segment now all right so here's a if you will a toy picture of how an ai algorithm might work so you take you have a little box here that i'm gonna i'm gonna show you what that looks like computation a little bit that's your ai that's your decision making and you feed it some information in our case the information we fed to our human uh reviewers were sex age uh the crime they were accused of the crime degree misdemeanor felony prior crimes juvenile felony priors and juvenile misdemeanor prior so these were the seven pieces of information we feed that information into well for humans into the brain and then we make a risk assessment and now we're gonna do is we're gonna feed that information into an ai algorithm a classifier if you will that then has to make a prediction okay so let's let's think a little bit about what that box might look like because if we're going to understand the race-blind problem and the accuracy problem we've got to start to get at what is happening in these ai algorithms okay so let's unpack that box a little bit all right now to keep things simple let's imagine i only have two pieces of information and you're going to see in a minute why i do that because it makes visualizing this box a little bit easier so imagine all you have at your access and i could have picked any two these are this is it's just it's random is how old somebody is and their total number of juvenile felonies that's all the information you have and your i algorithm now has to make a risk assessment okay so one way to think about this ai algorithm is to think about these two pieces of data as in terms of the euclidean plane the age of somebody from zero to whatever and the number of juvenile felony convictions just up on the vertical axis so we're going to train this algorithm so what does that mean we get a bunch of data where we like the broward county data that we use in our studies and every point here is an individual so this point corresponds to somebody that was this age and had very few juvenile felonies this data point corresponds to somebody who was younger and had more juvenile felonies and so on and so forth so every point in this two-dimensional space here corresponds to somebody that we uh that was arrested we have the historical data we followed them for two years and they did recidivate somewhere in that two-year period good training data now we have another body of training data of people who didn't recidivate and again every data point here i've just color coded the divide because these are people who did not recidivate right so so they were arrested followed them for two years clean record after that okay and that's their data now that's training data so what is the goal of an ai algorithm is now given that you've seen these patterns can you make predictions of people you've not seen in the same way when i started this lecture i said you may be you we may predict products you may like we may predict music that you may like we may predict whether you can give you a loan how you look at historical data you look at the patterns that emerge and you learn what is the likelihood of somebody not recidivating or somebody recidivating okay and there's lots of different ways of doing this ai machine learning i'm going to talk about one very very simple technique and here's the basic idea it's called a linear classifier which in this two-dimensional space again arbitrary axis age and juvenile felonies you draw a line this is why it's called a linear classifier because there's a linear separation between these clouds of data the red data points and the yellow data point now obviously in a seven dimensional space i can still do this but my separator is not a line it's a hyper plane so in 3d it would be a plane and 4d and beyond it's a hyperplane that's why i'm doing it in 2d because i can draw this as a line so the ai's goal is to learn this line that separates one class from another people who did recidivate from people who didn't recidivate so let's just talk about how that what that's going to look like so let's say this is i this is the classifier i learned this line now i get a new person that little blue dot right there and they're on the left side of the line which i've shaded red they are predicted to recidivate right that's the nature of recidivism by the way you can see the errors see that yellow dot right there in the yellow dot right there that's a mistake that's predicting somebody didn't would recidivate when they didn't and these red dots down here are the mistake the classifiers are not perfect but the majority of the yellow dots are there and the majority of the red dots appear and once i have learned that separating surface i can put any data point into the space right there and then i make a prediction which side of the line are you on so if you're on the left side i predict that you will you will recidivate and if you are on the bottom line like that blue point right there then i say you are not going to recidivate i have a classifier okay again not perfect but the majority of the yellow dots are there and the majority of the red dots are there so how do you learn that line lots of different ways to do it i'm going to just describe just to give you some intuition on how this works one classifier called the linear discriminant analysis it's also referred to as a fissure linear discriminant as well so an lda is the classifier i'm going to describe just very briefly all right here's our training data this is called so-called supervised learning i have training data and i know the labels i know that's a red i know that's a yellow dot and now my job is to learn a separating line higher dimensions it's a hyperplane that will separate it and how do i do that i need some objective function so here's the objective function i'm going to i'm going to change this line from this separating surface to a projection so now what i'm going to do is i'm going to find a line such that when i project all the data onto that one-dimensional subspace i'm going to accomplish two things the first thing is i'm going to minimize the within class variance so class is red did recidivate or yellow did not recidivate and what i want is i want to find a line that as i rotate through this space all of the red dots are bundled up really really tightly and all of the yellow dots are bundled up really tightly that's the within class red yellow variance so i want to minimize those variances so that all everybody's tightly bundled up together and at the same time i want to maximize the across class variance that is i want these red dots to be really tightly coupled and to be very far away from the yellow dots that are themselves very tightly coupled why why am i doing this well if i can drive these dots apart from each other and keep them coupled well then i can separate them i can draw a line down the middle and say red dots yellow dots one class the other class so this is the objective function for lda different types of machine learning albums have different objective functions not necessarily good or bad but this is probably the simplest one you will learn this in your machine learning class almost certainly in the first week it's really like the standard technique you always start with and then you go from there okay turns out by the way when you specify the problem as minimizing within class and maximizing a cross-class variance you can solve it using a generalized eigenvector problem and i only mentioned that because you should take a linear algebra class just because your computer scientists do not do not shy away from the mathematics in order to do almost anything really interesting in the space of ai machine learning pattern recognition image processing computer vision computer graphics robotics natural language processing the long list of really cool things out there you need to know a lot of math so linear algebra probability multivary calculus are really really good things to spend some time on so this lda reduces to a generalized eigenvector problem it can be solved with one line of python or matlab code really nice really simple very efficient now once i have that classifier i've learned this projection i'm going to project all the data onto it and now i have a classifier but i need to make a decision where is my boundary right so where do i so if everything projects onto this line right here where do i draw the separation that i'm going to predict all these are red and all these are white and yellow rather and i have a choice i can i can draw the line anywhere i want so let's say i drew the line here this will lead to a low false positive and a low true positive what do i mean by that so a false positive says that i take a yellow dot and i predict you as recidivating right i falsely accuse somebody being high risk but if i draw the line way up here very few yellow dots are going to be on this side of the boundary right there's just that one right there so i minimize the false positive but also notice that a lot of red dots are down here so i've also minimized the true positive as when somebody's high risk very few of them are being classified as high risk so i can trade off the errors that i'm comfortable with now i can move the line so if i move it down a little bit i've got a slightly higher true positive rate you can see more of the red dots are on the side but i've got another yellow dot got caught right and as i slide down what's going to happen well eventually i'm going to get to this point where i have a really high true positive rate most of the red dots are now being predicted as high risk but i have a really high false positive rate look at all the yellow dots that have now gotten caught in the web so i get to draw that line in the way that i want to balance these which mistakes do i want to minimize what is the accuracy that i want and i get to make that decision okay all right so that is in some ways the simplest possible ai that you can have for making this type of prediction okay lda linear discriminant analysis so now what i'm going to describe to you in the last segment of this talk is what happens when you have these seven things here and then what can we learn in terms of the commercial software its bias and why human performance is biased when they don't have race and why are they as good as a commercial software so once we're going to build a classifier based on some information over here and then we're going to see if we can get insights into those questions in this last segment so we'll be back in a few minutes to finish up 